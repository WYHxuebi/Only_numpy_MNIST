{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74fbdc7-ef21-4961-a459-0ecfa6b824a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from function.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "import numpy as np\n",
    "import gzip\n",
    "import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df41be9e-9076-4de8-986f-a435fc5feec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数定义\n",
    "learning_rate = 1e-3\n",
    "num_epoch = 50\n",
    "batch_size = 50\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08023c9-ca22-4caa-9b79-310f16eb656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练图像、训练标签路径\n",
    "train_images_filename = './data/train-images-idx3-ubyte.gz'\n",
    "train_labels_filename = './data/train-labels-idx1-ubyte.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2305f26e-5dba-421b-b813-555fd8725670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练图像\n",
    "tarin_images_loader = function.load_mnist_images(train_images_filename)\n",
    "\n",
    "# print(np.shape(tarin_images_loader))\n",
    "# print(type(tarin_images_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10d4e8b5-97c0-49dc-b7e4-ade4e3e9d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练标签\n",
    "tarin_labels_loader = function.load_mnist_labels(train_labels_filename)\n",
    "\n",
    "# print(np.shape(tarin_labels_loader))\n",
    "# print(type(tarin_labels_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc55f21-6ba8-4f8b-8ead-a2eb159aefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得batch数据以及batch数量\n",
    "train_images_batches, train_labels_batches = function.get_mini_batches(tarin_images_loader, tarin_labels_loader, batch_size, shuffle)\n",
    "num_batch = np.shape(train_images_batches)[0]\n",
    "\n",
    "# print(np.shape(train_images_batches))\n",
    "# print(np.shape(train_labels_batches))\n",
    "# print(type(train_images_batches))\n",
    "# print(type(train_labels_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46dff391-b9a7-4f19-bff6-91ad33f3fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化权重以及偏置，权重和偏置的范围为0~0.1\n",
    "layer1_weights = np.random.normal(loc=0.0, scale=0.01, size=(28*28, 256))\n",
    "layer2_weights = np.random.normal(loc=0.0, scale=0.01, size=(256, 128))\n",
    "layer3_weights = np.random.normal(loc=0.0, scale=0.01, size=(128, 64))\n",
    "layer4_weights = np.random.normal(loc=0.0, scale=0.01, size=(64, 10))\n",
    "layer1_bias = np.zeros([1, 256])\n",
    "layer2_bias = np.zeros([1, 128])\n",
    "layer3_bias = np.zeros([1, 64])\n",
    "layer4_bias = np.zeros([1, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ba17d9-9c43-4563-b630-645d206f11a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50,\tLoss: 0.9710312748580695\n",
      "Epoch 2/50,\tLoss: 0.4056331798315276\n",
      "Epoch 3/50,\tLoss: 0.32253656785060514\n",
      "Epoch 4/50,\tLoss: 0.292258996958827\n",
      "Epoch 5/50,\tLoss: 0.2595936424328404\n",
      "Epoch 6/50,\tLoss: 0.22050401350508714\n",
      "Epoch 7/50,\tLoss: 0.18667641065524798\n",
      "Epoch 8/50,\tLoss: 0.15472900071301865\n",
      "Epoch 9/50,\tLoss: 0.1266383038912786\n",
      "Epoch 10/50,\tLoss: 0.10118879527037933\n",
      "Epoch 11/50,\tLoss: 0.08007857067811816\n",
      "Epoch 12/50,\tLoss: 0.05965905413754383\n",
      "Epoch 13/50,\tLoss: 0.04167216379125465\n",
      "Epoch 14/50,\tLoss: 0.030185042553703755\n",
      "Epoch 15/50,\tLoss: 0.023286788120944202\n",
      "Epoch 16/50,\tLoss: 0.018399494002690312\n",
      "Epoch 17/50,\tLoss: 0.015638236516398164\n",
      "Epoch 18/50,\tLoss: 0.013364717819748692\n",
      "Epoch 19/50,\tLoss: 0.01185567258930217\n",
      "Epoch 20/50,\tLoss: 0.01001339854293544\n",
      "Epoch 21/50,\tLoss: 0.009210935024416448\n",
      "Epoch 22/50,\tLoss: 0.00837596914923731\n",
      "Epoch 23/50,\tLoss: 0.007799943424917587\n",
      "Epoch 24/50,\tLoss: 0.007373712874078065\n",
      "Epoch 25/50,\tLoss: 0.006798810943144229\n",
      "Epoch 26/50,\tLoss: 0.006743821562426389\n",
      "Epoch 27/50,\tLoss: 0.0062394192201429945\n",
      "Epoch 28/50,\tLoss: 0.006388344564244916\n",
      "Epoch 29/50,\tLoss: 0.006275069598945382\n",
      "Epoch 30/50,\tLoss: 0.006178258249861325\n",
      "Epoch 31/50,\tLoss: 0.005967329566897431\n",
      "Epoch 32/50,\tLoss: 0.005890126760869395\n",
      "Epoch 33/50,\tLoss: 0.005791718910006529\n",
      "Epoch 34/50,\tLoss: 0.00576439227013219\n",
      "Epoch 35/50,\tLoss: 0.00545636275066691\n",
      "Epoch 36/50,\tLoss: 0.005299649804301092\n",
      "Epoch 37/50,\tLoss: 0.00482595547745544\n",
      "Epoch 38/50,\tLoss: 0.004772376599935606\n",
      "Epoch 39/50,\tLoss: 0.004514177926138453\n",
      "Epoch 40/50,\tLoss: 0.004222258937090326\n",
      "Epoch 41/50,\tLoss: 0.004106757513610273\n",
      "Epoch 42/50,\tLoss: 0.003808491271586853\n",
      "Epoch 43/50,\tLoss: 0.003783458160202789\n",
      "Epoch 44/50,\tLoss: 0.0034755665270588152\n",
      "Epoch 45/50,\tLoss: 0.003328201857879839\n",
      "Epoch 46/50,\tLoss: 0.0031670285892327742\n",
      "Epoch 47/50,\tLoss: 0.0030514075130333184\n",
      "Epoch 48/50,\tLoss: 0.002834604052384008\n",
      "Epoch 49/50,\tLoss: 0.0027409933731841183\n",
      "Epoch 50/50,\tLoss: 0.002604520499738977\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    for batch in range(num_batch):\n",
    "        \n",
    "        # 获得 one batch的训练图像和标签\n",
    "        train_images = train_images_batches[batch]\n",
    "        train_labels = train_labels_batches[batch]\n",
    "\n",
    "        # 将train_images展平\n",
    "        train_images = np.reshape(train_images, (batch_size, -1))\n",
    "\n",
    "        # 将train_labels转换成独热码形式\n",
    "        train_labels = function.one_hot(train_labels, batch_size)\n",
    "        \n",
    "        # 前向传播\n",
    "        layer1_z = np.dot(train_images, layer1_weights) + layer1_bias\n",
    "        layer1_output = function.relu(layer1_z)\n",
    "        layer2_z = np.dot(layer1_output, layer2_weights) + layer2_bias\n",
    "        layer2_output = function.relu(layer2_z)\n",
    "        layer3_z = np.dot(layer2_output, layer3_weights) + layer3_bias\n",
    "        layer3_output = function.relu(layer3_z)\n",
    "        layer4_z = np.dot(layer3_output, layer4_weights) + layer4_bias\n",
    "        layer4_output = function.softmax(layer4_z)\n",
    "\n",
    "        # 计算损失\n",
    "        delta = 1e-7\n",
    "        loss = -np.sum(train_labels * np.log(layer4_output + delta)) / batch_size\n",
    "\n",
    "\n",
    "        # 反向传播\n",
    "        dL_dZ4 = (layer4_output - train_labels) / batch_size\n",
    "        dL_dW4 = np.dot(layer3_output.T, dL_dZ4)\n",
    "        dL_dB4 = np.sum(dL_dZ4, axis=0, keepdims=True)\n",
    "        \n",
    "        dL_dY3 = np.dot(dL_dZ4, layer4_weights.T)\n",
    "        dL_dZ3 = np.where(layer3_z>0, dL_dY3, 0)\n",
    "        dL_dW3 = np.dot(layer2_output.T, dL_dZ3)\n",
    "        dL_dB3 = np.sum(dL_dZ3, axis=0, keepdims=True)\n",
    "\n",
    "        dL_dY2 = np.dot(dL_dZ3, layer3_weights.T)\n",
    "        dL_dZ2 = np.where(layer2_z>0, dL_dY2, 0)\n",
    "        dL_dW2 = np.dot(layer1_output.T, dL_dZ2)\n",
    "        dL_dB2 = np.sum(dL_dZ2, axis=0, keepdims=True)\n",
    "\n",
    "        dL_dY1 = np.dot(dL_dZ2, layer2_weights.T)\n",
    "        dL_dZ1 = np.where(layer1_z>0, dL_dY1, 0)\n",
    "        dL_dW1 = np.dot(train_images.T, dL_dZ1)\n",
    "        dL_dB1 = np.sum(dL_dZ1, axis=0, keepdims=True)\n",
    "\n",
    "        # 更新权重和偏置\n",
    "        layer1_weights = layer1_weights - learning_rate * dL_dW1\n",
    "        layer1_bias = layer1_bias - learning_rate * dL_dB1\n",
    "        layer2_weights = layer2_weights - learning_rate * dL_dW2\n",
    "        layer2_bias = layer2_bias - learning_rate * dL_dB2\n",
    "        layer3_weights = layer3_weights - learning_rate * dL_dW3\n",
    "        layer3_bias = layer3_bias - learning_rate * dL_dB3\n",
    "        layer4_weights = layer4_weights - learning_rate * dL_dW4\n",
    "        layer4_bias = layer4_bias - learning_rate * dL_dB4\n",
    "    \n",
    "    # 保存权重和偏置\n",
    "    np.savez(f\"./saved_weights_biases/epoch_{epoch}_weights_bias.npz\", layer1_weights=layer1_weights, layer1_bias=layer1_bias,\n",
    "                                                                       layer2_weights=layer2_weights, layer2_bias=layer2_bias,\n",
    "                                                                       layer3_weights=layer3_weights, layer3_bias=layer3_bias,\n",
    "                                                                       layer4_weights=layer4_weights, layer4_bias=layer4_bias)\n",
    "\n",
    "    # 打印每个周期的训练损失\n",
    "    print(f\"Epoch {epoch + 1}/{num_epoch},\\tLoss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961e759-2c28-46b5-9013-6e24536f957e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
